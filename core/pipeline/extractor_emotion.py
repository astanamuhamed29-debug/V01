"""Emotion extraction pipeline: regex â†’ model â†’ LLM arbiter.

Architecture (3-layer hybrid):

Layer 1 â€” **Regex rules** (< 1 ms, always available)
    Fast keyword matching returning pre-calibrated VAD + intensity.
    Used as the baseline and as a fallback when deeper layers are
    unavailable or filtered out by confidence.

Layer 2 â€” **Model-based VAD regression + multi-label classification**
    Embedding-backed cosine-similarity to emotion-label centroids.
    Runs when an ``EmbeddingService`` is available.

Layer 3 â€” **LLM arbiter**
    Invoked **only** when:
      (a) confidence from layers 1-2 is below ``LLM_ARBITER_THRESHOLD``, or
      (b) sarcasm/irony is suspected, or
      (c) VAD from regex conflicts with model-based multi-label.
    Returns structured JSON with labels, VAD, confidence, cause,
    sarcasm flag.

Additional capabilities:
- **ERC context window**: last *N* user messages feed into the
  extraction so that conversational context shapes the result.
- **Personal baseline**: per-user neutral VAD point; all reported
  VAD values are expressed as deltas from baseline.
- Returns **confidence** âˆˆ [0, 1] for every emotion signal.
- Detects **implicit** emotions (no explicit keyword but context
  implies affect).
- Emits ``cause`` field when cause-phrase is found.

# NOTE: improved architecture â€” 3-layer hybrid with ERC context,
# personal baselines, and confidence-weighted signals replacing
# the old flat regex table.
"""

from __future__ import annotations

import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import TYPE_CHECKING, Any

from core.graph.model import Edge, Node

if TYPE_CHECKING:
    from core.context.session_memory import SessionMemory
    from core.llm_client import LLMClient

logger = logging.getLogger(__name__)


# â”€â”€ Tuneable constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CONFIDENCE_MIN: float = 0.3
LLM_ARBITER_THRESHOLD: float = 0.5
ERC_CONTEXT_WINDOW: int = 5
BASELINE_V: float = 0.0
BASELINE_A: float = 0.0
BASELINE_D: float = 0.0
IMPLICIT_MIN_CONTEXT: int = 2


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Data-transfer objects
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(slots=True)
class EmotionSignal:
    """Single emotion detected in a message."""

    label: str
    valence: float
    arousal: float
    dominance: float
    intensity: float
    confidence: float = 0.9
    source: str = "regex"        # "regex" | "model" | "llm"
    implicit: bool = False
    sarcasm: bool = False
    cause: str | None = None
    multi_labels: list[str] = field(default_factory=list)

    def to_metadata(self) -> dict[str, Any]:
        meta: dict[str, Any] = {
            "label": self.label,
            "valence": round(self.valence, 3),
            "arousal": round(self.arousal, 3),
            "dominance": round(self.dominance, 3),
            "intensity": round(self.intensity, 3),
            "confidence": round(self.confidence, 3),
            "source": self.source,
            "implicit": self.implicit,
            "sarcasm": self.sarcasm,
        }
        if self.cause:
            meta["cause"] = self.cause
        if self.multi_labels:
            meta["multi_labels"] = self.multi_labels
        return meta


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 1 â€” Regex rules (fast baseline)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EMOTION_RULES: list[tuple[re.Pattern[str], str, float, float, float, float]] = [
    (re.compile(r"\b(Ğ±Ğ¾ÑÑÑŒ|ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|ÑÑ‚Ñ€Ğ°Ñ…|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ¶)\w*\b"), "ÑÑ‚Ñ€Ğ°Ñ…", -0.8, 0.6, -0.6, 0.9),
    (re.compile(r"\b(ÑÑ‚Ñ‹Ğ´|ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾|ÑÑ‚Ñ‹Ğ´Ğ¾Ğ¼)\w*\b"), "ÑÑ‚Ñ‹Ğ´", -0.7, -0.2, -0.5, 0.8),
    (re.compile(r"\b(ÑƒÑÑ‚Ğ°Ğ»|ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ¸Ğ·Ğ¼Ğ¾Ñ‚Ğ°Ğ½)\w*\b"), "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ", -0.5, -0.4, -0.3, 0.7),
    (re.compile(r"\b(Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ·Ğ»ÑÑÑŒ|Ğ·Ğ»Ğ¾Ğ¹|Ğ±ĞµÑˆĞµĞ½|Ñ€Ğ°Ğ·Ğ´Ñ€Ğ°Ğ¶)\w*\b"), "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ", -0.7, 0.4, 0.7, 0.85),
    (re.compile(r"\b(Ğ²Ğ¸Ğ½Ğ°|Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚|Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚Ğ°)\w*\b"), "Ğ²Ğ¸Ğ½Ğ°", -0.6, -0.1, -0.4, 0.75),
    (re.compile(r"\b(Ğ¾Ğ±Ğ¸Ğ´|Ğ¾Ğ±Ğ¸Ğ´Ğ°|Ğ¾Ğ±Ğ¸Ğ´Ğ½Ğ¾|Ğ¾Ğ±Ğ¸Ğ¶ĞµĞ½|Ğ¾Ğ±Ğ¸Ğ¶ĞµĞ½Ğ°)\w*\b"), "Ğ¾Ğ±Ğ¸Ğ´Ğ°", -0.6, -0.2, -0.2, 0.7),
    (re.compile(r"\b(Ğ³Ñ€ÑƒÑÑ‚|Ğ¿ĞµÑ‡Ğ°Ğ»|Ñ‚Ğ¾ÑĞºĞ»|ÑƒĞ½Ñ‹Ğ»)\w*\b"), "Ğ³Ñ€ÑƒÑÑ‚ÑŒ", -0.7, -0.2, -0.4, 0.7),
    (re.compile(r"\b(Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ|Ñ€Ğ°Ğ´|ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²|Ğ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½|Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ°)\w*\b"), "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ", 0.8, 0.4, 0.4, 0.8),
    (re.compile(r"\b(ÑÑ‚ÑƒĞ¿Ğ¾Ñ€|Ğ·Ğ°Ğ¼ĞµÑ€|Ğ¾Ñ†ĞµĞ¿ĞµĞ½Ğµ)\w*\b"), "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€", -0.4, -0.3, -0.5, 0.65),
    (re.compile(r"\b(Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½|Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾|Ñ‚Ğ¾ÑˆĞ½Ğ¸Ñ‚)\w*\b"), "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ", -0.6, 0.2, 0.3, 0.75),
    (re.compile(r"\b(Ğ½Ğ°Ğ´ĞµĞ¶Ğ´|Ğ²ĞµÑ€Ñ|Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¼)\w*\b"), "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°", 0.5, 0.2, 0.3, 0.6),
    (re.compile(r"\b(Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²)\w*\b"), "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾", -0.7, -0.3, -0.5, 0.8),
    # NOTE: improved â€” added Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ, Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°, Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾ categories.
    (re.compile(r"Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ\s+ÑĞµĞ±Ñ|Ğ¿Ñ€ĞµĞ·Ğ¸Ñ€Ğ°Ñ\s+ÑĞµĞ±Ñ|Ñ\s+Ğ½Ğ¸ĞºÑ‡ĞµĞ¼"), "ÑÑ‚Ñ‹Ğ´", -0.8, -0.3, -0.6, 0.9),
]

# Cause-phrase patterns  # NOTE: improved â€” cause extraction via regex
_CAUSE_PATTERNS: list[re.Pattern[str]] = [
    re.compile(r"(?:Ğ¸Ğ·-Ğ·Ğ°|Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾|Ğ¾Ñ‚ Ñ‚Ğ¾Ğ³Ğ¾ Ñ‡Ñ‚Ğ¾|ĞºĞ¾Ğ³Ğ´Ğ°)\s+(.{3,60}?)(?:[.,!?;]|$)", re.IGNORECASE),
    re.compile(r"(?:Ğ¿Ğ¾ÑĞ»Ğµ|Ğ¿Ñ€Ğ¸|Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ)\s+(.{3,40}?)(?:[.,!?;]|$)", re.IGNORECASE),
]

# Sarcasm/irony heuristics  # NOTE: improved â€” sarcasm detection
_SARCASM_PATTERNS: list[re.Pattern[str]] = [
    re.compile(r"(?:Ğ°Ğ³Ğ°,? ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ¾|Ğ½Ñƒ Ğ´Ğ°,? Ğ½Ñƒ Ğ´Ğ°|ĞºĞ°Ğº Ğ¶Ğµ|Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½\w+,? Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾)", re.IGNORECASE),
    re.compile(r"(?:ğŸ˜‚|ğŸ™ƒ|ğŸ˜|ğŸ‘)\s*(?:Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½|Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½|Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½|Ñ‡ÑƒĞ´ĞµÑĞ½)", re.IGNORECASE),
]

# GoEmotions-compatible label mapping.
# NOTE: improved â€” multi-label bridge to GoEmotions taxonomy.
_LABEL_TO_GOEMOTION: dict[str, list[str]] = {
    "ÑÑ‚Ñ€Ğ°Ñ…": ["fear", "nervousness"],
    "ÑÑ‚Ñ‹Ğ´": ["embarrassment", "remorse"],
    "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ": ["annoyance", "disappointment"],
    "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ": ["anger", "annoyance"],
    "Ğ²Ğ¸Ğ½Ğ°": ["remorse"],
    "Ğ¾Ğ±Ğ¸Ğ´Ğ°": ["disappointment", "sadness"],
    "Ğ³Ñ€ÑƒÑÑ‚ÑŒ": ["sadness", "grief"],
    "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ": ["joy", "amusement"],
    "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€": ["confusion", "nervousness"],
    "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ": ["disgust"],
    "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°": ["optimism"],
    "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾": ["sadness", "disappointment"],
}


def _emotion_from_word(word: str) -> tuple[str, float, float, float, float] | None:
    """Match a single word against EMOTION_RULES. Public for tests."""
    probe = word.strip().lower()
    for pattern, label, valence, arousal, dominance, intensity in EMOTION_RULES:
        if pattern.search(probe):
            return label, valence, arousal, dominance, intensity
    return None


def _extract_cause(text: str) -> str | None:
    for pat in _CAUSE_PATTERNS:
        m = pat.search(text)
        if m:
            return m.group(1).strip()
    return None


def _detect_sarcasm(text: str) -> bool:
    return any(pat.search(text) for pat in _SARCASM_PATTERNS)


def _detect_emotions(lowered: str) -> list[EmotionSignal]:
    """Layer 1: fast regex detection returning EmotionSignal objects.

    Backward-compatible: still exposed as ``_detect_emotions`` but now
    returns rich ``EmotionSignal`` instances instead of bare tuples.
    """
    detected: list[EmotionSignal] = []
    seen: set[str] = set()

    between_match = re.search(
        r"(?:Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾\s+)?Ğ¼ĞµĞ¶Ğ´Ñƒ\s+([Ğ°-ÑÑ‘-]+)\s+Ğ¸\s+([Ğ°-ÑÑ‘-]+)",
        lowered,
        flags=re.IGNORECASE,
    )
    if between_match:
        for token in (between_match.group(1), between_match.group(2)):
            emo = _emotion_from_word(token)
            if emo and emo[0] not in seen:
                seen.add(emo[0])
                detected.append(EmotionSignal(
                    label=emo[0], valence=emo[1], arousal=emo[2],
                    dominance=emo[3], intensity=emo[4],
                    confidence=0.85, source="regex",
                    multi_labels=_LABEL_TO_GOEMOTION.get(emo[0], []),
                ))

    for pattern, label, v, a, d, i in EMOTION_RULES:
        if pattern.search(lowered) and label not in seen:
            seen.add(label)
            detected.append(EmotionSignal(
                label=label, valence=v, arousal=a,
                dominance=d, intensity=i,
                confidence=0.85, source="regex",
                multi_labels=_LABEL_TO_GOEMOTION.get(label, []),
            ))

    if detected:
        cause = _extract_cause(lowered)
        sarcasm = _detect_sarcasm(lowered)
        for sig in detected:
            sig.cause = cause
            sig.sarcasm = sarcasm

    return detected


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 2 â€” Model-based VAD regression (centroid projection)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NOTE: improved â€” pluggable model layer. Current impl uses cosine
# distance to emotion-label centroids as a lightweight proxy for a
# BERT-VAD regressor.

_CENTROID_TEXTS: dict[str, str] = {
    "ÑÑ‚Ñ€Ğ°Ñ…": "Ğ¼Ğ½Ğµ ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾, Ñ Ğ±Ğ¾ÑÑÑŒ",
    "ÑÑ‚Ñ‹Ğ´": "Ğ¼Ğ½Ğµ ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾ Ğ·Ğ° ÑĞµĞ±Ñ",
    "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ": "Ğ¼ĞµĞ½Ñ Ğ±ĞµÑĞ¸Ñ‚, Ñ Ğ·Ğ»ÑÑÑŒ",
    "Ğ³Ñ€ÑƒÑÑ‚ÑŒ": "Ğ¼Ğ½Ğµ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾ Ğ¸ Ğ¿ĞµÑ‡Ğ°Ğ»ÑŒĞ½Ğ¾",
    "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ": "Ñ Ñ€Ğ°Ğ´ Ğ¸ ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²",
    "Ğ²Ğ¸Ğ½Ğ°": "Ñ Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚, Ğ¼Ğ½Ğµ ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾",
    "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ": "Ñ ÑƒÑÑ‚Ğ°Ğ», Ğ½ĞµÑ‚ ÑĞ¸Ğ»",
    "Ğ¾Ğ±Ğ¸Ğ´Ğ°": "Ğ¼Ğ½Ğµ Ğ¾Ğ±Ğ¸Ğ´Ğ½Ğ¾",
    "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€": "Ñ Ğ² ÑÑ‚ÑƒĞ¿Ğ¾Ñ€Ğµ, Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ",
    "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ": "Ğ¼Ğ½Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾",
    "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°": "Ñ Ğ²ĞµÑ€Ñ, Ğ²ÑÑ‘ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑÑ",
    "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾": "Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº, Ğ½Ğ¸ĞºĞ¾Ğ³Ğ¾ Ñ€ÑĞ´Ğ¾Ğ¼",
}


async def _model_predict(
    text: str,
    embedding_service: Any | None,
) -> list[EmotionSignal]:
    """Layer 2: embedding-based emotion prediction."""
    if embedding_service is None:
        return []

    try:
        text_emb = await embedding_service.embed_text(text)
        if text_emb is None:
            return []
    except Exception as exc:
        logger.debug("Model layer embedding failed: %s", exc)
        return []

    from core.utils.math import cosine_similarity

    results: list[EmotionSignal] = []
    for label, centroid_text in _CENTROID_TEXTS.items():
        try:
            centroid_emb = await embedding_service.embed_text(centroid_text)
            if centroid_emb is None:
                continue
        except Exception:
            continue

        sim = cosine_similarity(text_emb, centroid_emb)
        if sim < 0.45:
            continue

        confidence = min(0.3 + (sim - 0.45) * (0.65 / 0.35), 0.99)

        rule_hit = None
        for _, rl, rv, ra, rd, ri in EMOTION_RULES:
            if rl == label:
                rule_hit = (rv, ra, rd, ri)
                break

        if rule_hit:
            v, a, d, i = rule_hit
        else:
            v, a, d, i = 0.0, 0.0, 0.0, 0.5

        results.append(EmotionSignal(
            label=label,
            valence=v, arousal=a, dominance=d, intensity=i,
            confidence=round(confidence, 3),
            source="model",
            multi_labels=_LABEL_TO_GOEMOTION.get(label, []),
        ))

    results.sort(key=lambda s: s.confidence, reverse=True)
    return results[:3]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 3 â€” LLM arbiter
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_LLM_EMOTION_PROMPT = """\
Ğ¢Ñ‹ â€” ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚ Ğ¿Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹.  ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸ Ğ²ĞµÑ€Ğ½Ğ¸
JSON (Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON, Ğ±ĞµĞ· markdown) ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹:
{
  "emotions": [
    {
      "label": "<Ğ¼ĞµÑ‚ĞºĞ° ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼>",
      "valence": <float -1..1>,
      "arousal": <float -1..1>,
      "dominance": <float -1..1>,
      "intensity": <float 0..1>,
      "confidence": <float 0..1>,
      "cause": "<Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¸Ğ»Ğ¸ null>",
      "sarcasm": <bool>,
      "implicit": <bool>
    }
  ]
}
ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¾Ñ‚ 0 Ğ´Ğ¾ 3 ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹
- implicit=true ĞµÑĞ»Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ° Ğ¿Ñ€ÑĞ¼Ğ¾, Ğ° ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
- Ğ£Ñ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ğ¹ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ¸ (ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚) Ğ¿Ñ€Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞµ
- Ğ•ÑĞ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ â€” Ğ²ĞµÑ€Ğ½Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¼Ğ°ÑÑĞ¸Ğ² emotions
"""


async def _llm_arbitrate(
    text: str,
    context_window: list[str],
    llm_client: "LLMClient | None",
) -> list[EmotionSignal]:
    """Layer 3: invoke LLM for ambiguous/low-confidence cases."""
    if llm_client is None:
        return []

    context_block = "\n".join(f"[ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚] {msg}" for msg in context_window[-ERC_CONTEXT_WINDOW:])
    user_payload = f"{context_block}\n\n[Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ] {text}" if context_block else text

    try:
        raw = await llm_client.extract_emotion(user_payload, "FEELING_REPORT")
    except Exception as exc:
        logger.warning("LLM emotion arbiter failed: %s", exc)
        return []

    if isinstance(raw, str):
        try:
            raw = json.loads(raw)
        except json.JSONDecodeError:
            return []

    if not isinstance(raw, dict):
        return []

    emotions_raw = raw.get("emotions", [])
    if not isinstance(emotions_raw, list):
        return []

    signals: list[EmotionSignal] = []
    for item in emotions_raw[:3]:
        if not isinstance(item, dict) or "label" not in item:
            continue
        signals.append(EmotionSignal(
            label=str(item["label"]),
            valence=float(item.get("valence", 0)),
            arousal=float(item.get("arousal", 0)),
            dominance=float(item.get("dominance", 0)),
            intensity=float(item.get("intensity", 0.5)),
            confidence=float(item.get("confidence", 0.7)),
            source="llm",
            implicit=bool(item.get("implicit", False)),
            sarcasm=bool(item.get("sarcasm", False)),
            cause=item.get("cause"),
            multi_labels=_LABEL_TO_GOEMOTION.get(str(item["label"]), []),
        ))

    return signals


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ERC context window  # NOTE: improved â€” conversational context
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _build_context_window(
    session_memory: "SessionMemory | None",
    user_id: str,
) -> list[str]:
    if session_memory is None:
        return []
    ctx = session_memory.get_context(user_id, max_messages=ERC_CONTEXT_WINDOW * 2)
    return [m["text"] for m in ctx if m.get("role") == "user"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Personal baseline  # NOTE: improved â€” per-user neutral VAD point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(slots=True)
class PersonalBaseline:
    """Per-user neutral VAD reference point (EMA)."""

    valence: float = BASELINE_V
    arousal: float = BASELINE_A
    dominance: float = BASELINE_D
    sample_count: int = 0

    def update(self, v: float, a: float, d: float, alpha: float = 0.05) -> None:
        if self.sample_count == 0:
            self.valence = v
            self.arousal = a
            self.dominance = d
        else:
            self.valence += alpha * (v - self.valence)
            self.arousal += alpha * (a - self.arousal)
            self.dominance += alpha * (d - self.dominance)
        self.sample_count += 1

    def delta(self, v: float, a: float, d: float) -> tuple[float, float, float]:
        return (v - self.valence, a - self.arousal, d - self.dominance)

    def to_dict(self) -> dict[str, Any]:
        return {
            "baseline_v": round(self.valence, 3),
            "baseline_a": round(self.arousal, 3),
            "baseline_d": round(self.dominance, 3),
            "baseline_samples": self.sample_count,
        }


_baselines: dict[str, PersonalBaseline] = {}


def get_baseline(user_id: str) -> PersonalBaseline:
    if user_id not in _baselines:
        _baselines[user_id] = PersonalBaseline()
    return _baselines[user_id]


def load_baseline_from_meta(user_id: str, meta: dict[str, Any]) -> None:
    bl = PersonalBaseline(
        valence=float(meta.get("baseline_v", BASELINE_V)),
        arousal=float(meta.get("baseline_a", BASELINE_A)),
        dominance=float(meta.get("baseline_d", BASELINE_D)),
        sample_count=int(meta.get("baseline_samples", 0)),
    )
    _baselines[user_id] = bl


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Fusion / merge logic
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _merge_signals(
    regex_signals: list[EmotionSignal],
    model_signals: list[EmotionSignal],
    llm_signals: list[EmotionSignal],
) -> list[EmotionSignal]:
    """Fuse signals from all layers: prefer higher-confidence source.

    Priority: LLM > model > regex (when same label appears).
    # NOTE: improved â€” multi-source fusion with confidence ranking.
    """
    by_label: dict[str, EmotionSignal] = {}

    for sig in regex_signals:
        by_label[sig.label] = sig
    for sig in model_signals:
        existing = by_label.get(sig.label)
        if existing is None or sig.confidence > existing.confidence:
            by_label[sig.label] = sig
    for sig in llm_signals:
        existing = by_label.get(sig.label)
        if existing is None or sig.confidence >= existing.confidence:
            by_label[sig.label] = sig

    result = [s for s in by_label.values() if s.confidence >= EMOTION_CONFIDENCE_MIN]
    result.sort(key=lambda s: s.confidence, reverse=True)
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Guard regex
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_EMOTION_GUARD = re.compile(
    r"(Ğ±Ğ¾ÑÑÑŒ|ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|ÑÑ‚Ñ€Ğ°Ñ…|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ¶|Ñ€Ğ°Ğ´|Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ|Ğ·Ğ»ÑÑÑŒ|Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ±ĞµÑˆĞµĞ½|Ñ€Ğ°Ğ·Ğ´Ñ€Ğ°Ğ¶"
    r"|Ğ³Ñ€ÑƒÑÑ‚|Ğ¿ĞµÑ‡Ğ°Ğ»|Ñ‚Ğ¾ÑĞºĞ»|ÑƒĞ½Ñ‹Ğ»|ÑÑ‚Ñ‹Ğ´|ÑƒÑÑ‚Ğ°Ğ»|Ğ²Ğ¸Ğ½Ğ°|Ğ¾Ğ±Ğ¸Ğ´|ÑÑ‚ÑƒĞ¿Ğ¾Ñ€|Ğ·Ğ°Ğ¼ĞµÑ€|Ğ¾Ñ†ĞµĞ¿ĞµĞ½"
    r"|Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒÑ|Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ\s+ÑĞµĞ±Ñ|Ğ¿Ñ€ĞµĞ·Ğ¸Ñ€Ğ°Ñ\s+ÑĞµĞ±Ñ|Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½|Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾|Ñ‚Ğ¾ÑˆĞ½Ğ¸Ñ‚"
    r"|Ğ½Ğ°Ğ´ĞµĞ¶Ğ´|Ğ²ĞµÑ€Ñ|Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¼|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²|Ğ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½|Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ°|ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²"
    r"|Ğ¿Ğ»Ğ¾Ñ…Ğ¾|Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾|Ğ¾Ğº|Ğ¿Ğ°Ğ½Ğ¸Ğº|Ğ½ĞµÑ€Ğ²Ğ½Ğ¸Ñ‡|Ğ²Ğ¾Ğ»Ğ½Ñƒ|Ğ±ĞµÑĞ¿Ğ¾ĞºĞ¾Ğ¹)",
    re.IGNORECASE,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Public API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def extract(
    user_id: str,
    text: str,
    intent: str,
    person_id: str,
    *,
    session_memory: "SessionMemory | None" = None,
    llm_client: "LLMClient | None" = None,
    embedding_service: Any | None = None,
) -> tuple[list[Node], list[Edge]]:
    """Full emotion extraction pipeline.

    Parameters
    ----------
    user_id, text, intent, person_id : str
        Core identification / message fields.
    session_memory : SessionMemory, optional
        For ERC context window.
    llm_client : LLMClient, optional
        For Layer 3 arbitration.
    embedding_service : EmbeddingService, optional
        For Layer 2 model-based prediction.

    Returns
    -------
    tuple[list[Node], list[Edge]]
        Emotion/Soma nodes and FEELS/EXPRESSED_AS edges.
    """
    nodes: list[Node] = []
    edges: list[Edge] = []
    lowered = text.lower()

    # ERC context window  # NOTE: improved â€” contextual emotion recognition
    context_window = _build_context_window(session_memory, user_id)

    # â”€â”€ Layer 1: regex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    regex_signals = _detect_emotions(lowered)

    # Guard: skip deep layers if no emotional keywords AND intent
    # is not feeling-related.
    if not regex_signals and not _EMOTION_GUARD.search(lowered):
        if intent not in ("FEELING_REPORT", "REFLECTION"):
            return nodes, edges

    # â”€â”€ Layer 2: model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model_signals = await _model_predict(text, embedding_service)

    # â”€â”€ Layer 3: LLM arbiter (conditional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    llm_signals: list[EmotionSignal] = []
    needs_arbiter = (
        (regex_signals and all(s.confidence < LLM_ARBITER_THRESHOLD for s in regex_signals))
        or _detect_sarcasm(lowered)
        or (
            regex_signals
            and model_signals
            and regex_signals[0].label != model_signals[0].label
        )
        or (not regex_signals and intent == "FEELING_REPORT")
        or (
            not regex_signals
            and len(context_window) >= IMPLICIT_MIN_CONTEXT
            and intent in ("FEELING_REPORT", "REFLECTION")
        )
    )
    if needs_arbiter:
        llm_signals = await _llm_arbitrate(text, context_window, llm_client)

    # â”€â”€ Fusion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    merged = _merge_signals(regex_signals, model_signals, llm_signals)

    if not merged:
        return nodes, edges

    # â”€â”€ Personal baseline update â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    baseline = get_baseline(user_id)
    for sig in merged:
        baseline.update(sig.valence, sig.arousal, sig.dominance)

    # â”€â”€ Build nodes & edges â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # NOTE: improved â€” key is now None (unique UUID per signal)
    # instead of date-based key that collapsed intra-session trajectory.
    now_iso = datetime.now(timezone.utc).isoformat()
    emotion_nodes: list[Node] = []

    for sig in merged:
        dv, da, dd = baseline.delta(sig.valence, sig.arousal, sig.dominance)
        meta = sig.to_metadata()
        meta["delta_v"] = round(dv, 3)
        meta["delta_a"] = round(da, 3)
        meta["delta_d"] = round(dd, 3)
        meta["created_at"] = now_iso

        emotion = Node(
            user_id=user_id,
            type="EMOTION",
            key=None,
            metadata=meta,
        )
        emotion_nodes.append(emotion)
        nodes.append(emotion)
        edges.append(Edge(
            user_id=user_id,
            source_node_id=person_id,
            target_node_id=emotion.id,
            relation="FEELS",
        ))

    # â”€â”€ Somatic markers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    body_match = re.search(
        r"\b(Ğ² Ğ³Ñ€ÑƒĞ´Ğ¸|Ğ² Ğ¶Ğ¸Ğ²Ğ¾Ñ‚Ğµ|Ğ² Ğ³Ğ¾Ñ€Ğ»Ğµ|Ğ² Ğ¿Ğ»ĞµÑ‡Ğ°Ñ…|Ğ² ÑˆĞµĞµ|Ğ² Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğµ|Ğ² ÑĞ¿Ğ¸Ğ½Ğµ)\b",
        lowered,
    )
    if body_match:
        location = body_match.group(1)
        soma = Node(
            user_id=user_id,
            type="SOMA",
            key=None,
            metadata={"location": location, "sensation": "tension"},
        )
        nodes.append(soma)
        if emotion_nodes:
            edges.append(Edge(
                user_id=user_id,
                source_node_id=emotion_nodes[0].id,
                target_node_id=soma.id,
                relation="EXPRESSED_AS",
            ))

    return nodes, edges
