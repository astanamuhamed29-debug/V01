"""Emotion extraction pipeline: regex â†’ model â†’ LLM arbiter.

Architecture (3-layer hybrid):

Layer 1 â€” **Regex rules** (< 1 ms, always available)
    Fast keyword matching returning pre-calibrated VAD + intensity.
    Used as the baseline and as a fallback when deeper layers are
    unavailable or filtered out by confidence.

Layer 2 â€” **Model-based VAD regression + multi-label classification**
    Embedding-backed cosine-similarity to emotion-label centroids.
    Runs when an ``EmbeddingService`` is available.

Layer 3 â€” **LLM arbiter**
    Invoked **only** when:
      (a) confidence from layers 1-2 is below ``LLM_ARBITER_THRESHOLD``, or
      (b) sarcasm/irony is suspected, or
      (c) VAD from regex conflicts with model-based multi-label.
    Returns structured JSON with labels, VAD, confidence, cause,
    sarcasm flag.

Additional capabilities:
- **ERC context window**: last *N* user messages feed into the
  extraction so that conversational context shapes the result.
- **Personal baseline**: per-user neutral VAD point; all reported
  VAD values are expressed as deltas from baseline.
- Returns **confidence** âˆˆ [0, 1] for every emotion signal.
- Detects **implicit** emotions (no explicit keyword but context
  implies affect).
- Emits ``cause`` field when cause-phrase is found.

# NOTE: improved architecture â€” 3-layer hybrid with ERC context,
# personal baselines, and confidence-weighted signals replacing
# the old flat regex table.
"""

from __future__ import annotations

import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import TYPE_CHECKING, Any

from core.graph.model import Edge, Node

if TYPE_CHECKING:
    from core.context.session_memory import SessionMemory
    from core.llm_client import LLMClient

logger = logging.getLogger(__name__)


# â”€â”€ Tuneable constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CONFIDENCE_MIN: float = 0.3
LLM_ARBITER_THRESHOLD: float = 0.5
ERC_CONTEXT_WINDOW: int = 5
BASELINE_V: float = 0.0
BASELINE_A: float = 0.0
BASELINE_D: float = 0.0
IMPLICIT_MIN_CONTEXT: int = 2
_BASE_CONFIDENCE: float = 0.75  # base for dynamic confidence calculation

# â”€â”€ Negation / Intensifier / Uncertainty word-sets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_NEGATED_DIMINISHERS: frozenset[str] = frozenset({
    "Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ", "Ğ½Ğµ ÑĞ¸Ğ»ÑŒĞ½Ğ¾", "Ğ½Ğµ Ğ¾ÑĞ¾Ğ±Ğ¾", "Ğ½Ğµ Ñ‚Ğ°Ğº ÑƒĞ¶", "Ğ½Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼",
})
_AMPLIFIER_WORDS: frozenset[str] = frozenset({
    "Ğ¾Ñ‡ĞµĞ½ÑŒ", "ÑĞ¸Ğ»ÑŒĞ½Ğ¾", "Ğ´Ğ¸ĞºĞ¾", "ÑƒĞ¶Ğ°ÑĞ½Ğ¾", "Ğ½ĞµĞ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾",
    "ĞºÑ€Ğ°Ğ¹Ğ½Ğµ", "Ñ‡Ñ€ĞµĞ·Ğ²Ñ‹Ñ‡Ğ°Ğ¹Ğ½Ğ¾", "Ğ¶ÑƒÑ‚ĞºĞ¾", "Ğ°Ğ´ÑĞºĞ¸", "Ğ±ĞµĞ·ÑƒĞ¼Ğ½Ğ¾",
})
_DIMINISHER_WORDS: frozenset[str] = frozenset({
    "Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾", "ÑĞ»ĞµĞ³ĞºĞ°", "Ñ‡ÑƒÑ‚ÑŒ", "Ğ»ĞµĞ³ĞºĞ¾", "ĞµĞ´Ğ²Ğ°", "ĞµĞ»Ğµ", "ÑĞ»Ğ°Ğ±Ğ¾",
})
_NEGATION_WORDS: frozenset[str] = frozenset({
    "Ğ½Ğµ", "Ğ½ĞµÑ‚", "Ğ½ĞµÑ‚Ñƒ", "Ğ½Ğ¸", "Ğ±ĞµĞ·", "Ğ½Ğ¸ĞºĞ°Ğº", "Ğ½Ğ¸ÑĞºĞ¾Ğ»ÑŒĞºĞ¾", "Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ°",
})
_UNCERTAINTY_WORDS: frozenset[str] = frozenset({
    "Ğ¼Ğ¾Ğ¶ĞµÑ‚", "Ğ½Ğ°Ğ²ĞµÑ€Ğ½Ğ¾Ğµ", "ĞºĞ°Ğ¶ĞµÑ‚ÑÑ", "Ğ²Ñ€Ğ¾Ğ´Ğµ", "Ğ±ÑƒĞ´Ñ‚Ğ¾",
    "ÑĞ»Ğ¾Ğ²Ğ½Ğ¾", "Ñ‚Ğ¸Ğ¿Ğ°", "Ğ¿Ğ¾Ñ…Ğ¾Ğ´Ñƒ",
})


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Data-transfer objects
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(slots=True)
class EmotionSignal:
    """Single emotion detected in a message."""

    label: str
    valence: float
    arousal: float
    dominance: float
    intensity: float
    confidence: float = 0.9
    source: str = "regex"        # "regex" | "model" | "llm"
    implicit: bool = False
    sarcasm: bool = False
    cause: str | None = None
    multi_labels: list[str] = field(default_factory=list)
    ambivalent: bool = False

    def to_metadata(self) -> dict[str, Any]:
        meta: dict[str, Any] = {
            "label": self.label,
            "valence": round(self.valence, 3),
            "arousal": round(self.arousal, 3),
            "dominance": round(self.dominance, 3),
            "intensity": round(self.intensity, 3),
            "confidence": round(self.confidence, 3),
            "source": self.source,
            "implicit": self.implicit,
            "sarcasm": self.sarcasm,
        }
        if self.cause:
            meta["cause"] = self.cause
        if self.multi_labels:
            meta["multi_labels"] = self.multi_labels
        if self.ambivalent:
            meta["ambivalent"] = True
        return meta


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Research-backed VAD norms (Warriner et al., 2013 â€” adapted)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# (valence, arousal, dominance, default_intensity)  â€” scales [-1..1] / [0..1]

_VAD_NORMS: dict[str, tuple[float, float, float, float]] = {
    "ÑÑ‚Ñ€Ğ°Ñ…":        (-0.55,  0.33, -0.39, 0.85),
    "ÑÑ‚Ñ‹Ğ´":         (-0.63,  0.01, -0.55, 0.80),
    "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ":    (-0.48, -0.65, -0.32, 0.70),
    "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ":       (-0.67,  0.54,  0.05, 0.85),
    "Ğ²Ğ¸Ğ½Ğ°":         (-0.72,  0.02, -0.43, 0.75),
    "Ğ¾Ğ±Ğ¸Ğ´Ğ°":        (-0.70,  0.16, -0.47, 0.70),
    "Ğ³Ñ€ÑƒÑÑ‚ÑŒ":       (-0.73, -0.38, -0.39, 0.70),
    "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ":      ( 0.87,  0.37,  0.55, 0.80),
    "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€":       (-0.16, -0.40, -0.38, 0.65),
    "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ":   (-0.64,  0.23,  0.04, 0.75),
    "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°":      ( 0.63,  0.14,  0.38, 0.60),
    "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾":  (-0.71, -0.12, -0.51, 0.80),
}


def _vad(label: str) -> tuple[float, float, float, float]:
    """Look up VAD + intensity from research norms."""
    return _VAD_NORMS.get(label, (0.0, 0.0, 0.0, 0.5))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 1 â€” Regex rules (fast baseline)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Patterns reference labels; VAD values come from ``_VAD_NORMS``.
# Morphology: every stem family is covered (Ñ‚Ñ€ĞµĞ²Ğ¾Ğ¶ + Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³, etc.)

_LABEL_PATTERNS: list[tuple[str, str]] = [
    ("ÑÑ‚Ñ€Ğ°Ñ…",       r"\b(Ğ±Ğ¾ÑÑÑŒ|ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|ÑÑ‚Ñ€Ğ°Ñ…|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ¶|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³|Ğ±ĞµÑĞ¿Ğ¾ĞºĞ¾Ğ¹|Ğ¿Ğ°Ğ½Ğ¸Ğº|Ğ½ĞµÑ€Ğ²Ğ½Ğ¸Ñ‡|Ğ²Ğ¾Ğ»Ğ½Ñƒ)\w*\b"),
    ("ÑÑ‚Ñ‹Ğ´",        r"\b(ÑÑ‚Ñ‹Ğ´|ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾|ÑÑ‚Ñ‹Ğ´Ğ¾Ğ¼)\w*\b"),
    ("ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ",   r"\b(ÑƒÑÑ‚Ğ°Ğ»|ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ¸Ğ·Ğ¼Ğ¾Ñ‚Ğ°Ğ½|Ğ²Ñ‹Ğ¼Ğ¾Ñ‚Ğ°Ğ½)\w*\b"),
    ("Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ",      r"\b(Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ·Ğ»ÑÑÑŒ|Ğ·Ğ»Ğ¾Ğ¹|Ğ±ĞµÑˆĞµĞ½|Ñ€Ğ°Ğ·Ğ´Ñ€Ğ°Ğ¶|Ğ±ĞµÑĞ¸Ñ‚|Ğ²Ğ·Ğ±ĞµÑˆ|Ñ€Ğ°Ğ·ÑŠÑÑ€ĞµĞ½)\w*\b"),
    ("Ğ²Ğ¸Ğ½Ğ°",        r"\b(Ğ²Ğ¸Ğ½Ğ°|Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚|Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚Ğ°)\w*\b"),
    ("Ğ¾Ğ±Ğ¸Ğ´Ğ°",       r"\b(Ğ¾Ğ±Ğ¸Ğ´|Ğ¾Ğ±Ğ¸Ğ´Ğ°|Ğ¾Ğ±Ğ¸Ğ´Ğ½Ğ¾|Ğ¾Ğ±Ğ¸Ğ¶ĞµĞ½|Ğ¾Ğ±Ğ¸Ğ¶ĞµĞ½Ğ°)\w*\b"),
    ("Ğ³Ñ€ÑƒÑÑ‚ÑŒ",      r"\b(Ğ³Ñ€ÑƒÑÑ‚|Ğ¿ĞµÑ‡Ğ°Ğ»|Ñ‚Ğ¾ÑĞºĞ»|Ñ‚Ğ¾ÑĞº|ÑƒĞ½Ñ‹Ğ»|ÑƒĞ½Ñ‹Ğ½Ğ¸)\w*\b"),
    ("Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ",     r"\b(Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ|Ñ€Ğ°Ğ´|ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²|Ğ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½|Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ°|Ğ²Ğ¾ÑÑ‚Ğ¾Ñ€Ğ³)\w*\b"),
    ("ÑÑ‚ÑƒĞ¿Ğ¾Ñ€",      r"\b(ÑÑ‚ÑƒĞ¿Ğ¾Ñ€|Ğ·Ğ°Ğ¼ĞµÑ€|Ğ¾Ñ†ĞµĞ¿ĞµĞ½Ğµ)\w*\b"),
    ("Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ",  r"\b(Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½|Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾|Ñ‚Ğ¾ÑˆĞ½Ğ¸Ñ‚|Ğ¼ĞµÑ€Ğ·Ğº|Ğ³Ğ°Ğ´Ğº)\w*\b"),
    ("Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°",     r"\b(Ğ½Ğ°Ğ´ĞµĞ¶Ğ´|Ğ²ĞµÑ€Ñ|Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¼)\w*\b"),
    ("Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾", r"\b(Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²)\w*\b"),
]

EMOTION_RULES: list[tuple[re.Pattern[str], str, float, float, float, float]] = []
for _lbl, _pat in _LABEL_PATTERNS:
    _v, _a, _d, _i = _vad(_lbl)
    EMOTION_RULES.append((re.compile(_pat), _lbl, _v, _a, _d, _i))

# Special multi-word rules
_sv, _sa, _sd, _si = _vad("ÑÑ‚Ñ‹Ğ´")
EMOTION_RULES.append(
    (re.compile(r"Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ\s+ÑĞµĞ±Ñ|Ğ¿Ñ€ĞµĞ·Ğ¸Ñ€Ğ°Ñ\s+ÑĞµĞ±Ñ|Ñ\s+Ğ½Ğ¸ĞºÑ‡ĞµĞ¼"), "ÑÑ‚Ñ‹Ğ´", _sv, _sa, _sd, _si),
)

# Cause-phrase patterns  # NOTE: improved â€” cause extraction via regex
_CAUSE_PATTERNS: list[re.Pattern[str]] = [
    re.compile(r"(?:Ğ¸Ğ·-Ğ·Ğ°|Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼Ñƒ Ñ‡Ñ‚Ğ¾|Ğ¾Ñ‚ Ñ‚Ğ¾Ğ³Ğ¾ Ñ‡Ñ‚Ğ¾|ĞºĞ¾Ğ³Ğ´Ğ°)\s+(.{3,60}?)(?:[.,!?;]|$)", re.IGNORECASE),
    re.compile(r"(?:Ğ¿Ğ¾ÑĞ»Ğµ|Ğ¿Ñ€Ğ¸|Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ)\s+(.{3,40}?)(?:[.,!?;]|$)", re.IGNORECASE),
]

# Sarcasm/irony heuristics  # NOTE: improved â€” sarcasm detection
_SARCASM_PATTERNS: list[re.Pattern[str]] = [
    re.compile(r"(?:Ğ°Ğ³Ğ°,? ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ¾|Ğ½Ñƒ Ğ´Ğ°,? Ğ½Ñƒ Ğ´Ğ°|ĞºĞ°Ğº Ğ¶Ğµ|Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½\w+,? Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾)", re.IGNORECASE),
    re.compile(r"(?:ğŸ˜‚|ğŸ™ƒ|ğŸ˜|ğŸ‘)\s*(?:Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½|Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½|Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½|Ñ‡ÑƒĞ´ĞµÑĞ½)", re.IGNORECASE),
]

# GoEmotions-compatible label mapping.
# NOTE: improved â€” multi-label bridge to GoEmotions taxonomy.
_LABEL_TO_GOEMOTION: dict[str, list[str]] = {
    "ÑÑ‚Ñ€Ğ°Ñ…": ["fear", "nervousness"],
    "ÑÑ‚Ñ‹Ğ´": ["embarrassment", "remorse"],
    "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ": ["annoyance", "disappointment"],
    "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ": ["anger", "annoyance"],
    "Ğ²Ğ¸Ğ½Ğ°": ["remorse"],
    "Ğ¾Ğ±Ğ¸Ğ´Ğ°": ["disappointment", "sadness"],
    "Ğ³Ñ€ÑƒÑÑ‚ÑŒ": ["sadness", "grief"],
    "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ": ["joy", "amusement"],
    "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€": ["confusion", "nervousness"],
    "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ": ["disgust"],
    "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°": ["optimism"],
    "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾": ["sadness", "disappointment"],
}


def _emotion_from_word(word: str) -> tuple[str, float, float, float, float] | None:
    """Match a single word against EMOTION_RULES. Public for tests."""
    probe = word.strip().lower()
    for pattern, label, valence, arousal, dominance, intensity in EMOTION_RULES:
        if pattern.search(probe):
            return label, valence, arousal, dominance, intensity
    return None


def _extract_cause(text: str) -> str | None:
    for pat in _CAUSE_PATTERNS:
        m = pat.search(text)
        if m:
            return m.group(1).strip()
    return None


def _detect_sarcasm(text: str) -> bool:
    return any(pat.search(text) for pat in _SARCASM_PATTERNS)


# â”€â”€ Context analysers (negation, intensifiers, uncertainty) â”€â”€â”€â”€â”€â”€â”€

def _analyze_context(text: str, match_start: int) -> tuple[bool, float, float]:
    """Analyze context around an emotion-keyword match position.

    Returns ``(is_negated, intensity_multiplier, confidence_adjustment)``.

    Priority order:
    1. Multi-word diminishers that contain negation (``Ğ½Ğµ Ğ¾Ñ‡ĞµĞ½ÑŒ`` etc.) â†’
       treated as diminisher, **not** as negation.
    2. Simple diminishers (``Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾``, ``ÑĞ»ĞµĞ³ĞºĞ°``, â€¦) â†’ Ã—0.5 intensity.
    3. Amplifiers (``Ğ¾Ñ‡ĞµĞ½ÑŒ``, ``ÑĞ¸Ğ»ÑŒĞ½Ğ¾``, â€¦) â†’ Ã—1.3 intensity, +0.10 conf.
    4. Plain negation (``Ğ½Ğµ``, ``Ğ½ĞµÑ‚``, â€¦) â†’ skip the emotion.
    5. Uncertainty markers checked globally â†’ âˆ’0.15 conf.
    """
    before = text[:match_start].strip().lower()
    words_before = before.split()[-4:]
    chunk = " ".join(words_before)

    is_negated = False
    intensity_mult = 1.0
    conf_adj = 0.0

    # 1. Multi-word diminishers containing negation word (word-boundary match)
    if any(re.search(rf"\b{re.escape(nd)}\b", chunk) for nd in _NEGATED_DIMINISHERS):
        intensity_mult = 0.5
    # 2. Simple diminishers
    elif any(w in _DIMINISHER_WORDS for w in words_before[-3:]):
        intensity_mult = 0.5
    # 3. Amplifiers
    elif any(w in _AMPLIFIER_WORDS for w in words_before[-3:]):
        intensity_mult = 1.3
        conf_adj = 0.10
    # 4. Plain negation
    elif any(w in _NEGATION_WORDS for w in words_before[-3:]):
        is_negated = True

    # 5. Uncertainty markers (checked across the whole text)
    if any(w in _UNCERTAINTY_WORDS for w in text.lower().split()):
        conf_adj -= 0.15

    return is_negated, intensity_mult, conf_adj


def _detect_emotions(lowered: str) -> list[EmotionSignal]:
    """Layer 1: fast regex detection returning EmotionSignal objects.

    Improvements over the previous version:
    - **Negation handling**: ``Ñ Ğ½Ğµ Ğ±Ğ¾ÑÑÑŒ`` no longer produces a fear signal.
    - **Intensifiers / diminutives**: ``Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾`` amplifies intensity;
      ``Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾`` dampens it.
    - **Dynamic confidence**: base 0.75 adjusted by modifiers, cause presence,
      and uncertainty markers instead of a flat 0.85.
    """
    detected: list[EmotionSignal] = []
    seen: set[str] = set()
    cause = _extract_cause(lowered)
    sarcasm = _detect_sarcasm(lowered)

    # â”€â”€ "Ğ¼ĞµĞ¶Ğ´Ñƒ X Ğ¸ Y" pattern â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    between_match = re.search(
        r"(?:Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾\s+)?Ğ¼ĞµĞ¶Ğ´Ñƒ\s+([Ğ°-ÑÑ‘-]+)\s+Ğ¸\s+([Ğ°-ÑÑ‘-]+)",
        lowered,
        flags=re.IGNORECASE,
    )
    if between_match:
        for token in (between_match.group(1), between_match.group(2)):
            emo = _emotion_from_word(token)
            if emo and emo[0] not in seen:
                seen.add(emo[0])
                detected.append(EmotionSignal(
                    label=emo[0], valence=emo[1], arousal=emo[2],
                    dominance=emo[3], intensity=emo[4],
                    confidence=_BASE_CONFIDENCE, source="regex",
                    cause=cause, sarcasm=sarcasm,
                    multi_labels=_LABEL_TO_GOEMOTION.get(emo[0], []),
                ))

    # â”€â”€ Main pattern matching with context analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for pattern, label, v, a, d, base_intensity in EMOTION_RULES:
        if label in seen:
            continue
        m = pattern.search(lowered)
        if not m:
            continue

        is_negated, intensity_mult, conf_adj = _analyze_context(lowered, m.start())
        if is_negated:
            continue  # skip negated emotions

        # Dynamic confidence
        confidence = _BASE_CONFIDENCE + conf_adj
        if cause:
            confidence += 0.05
        confidence = max(EMOTION_CONFIDENCE_MIN, min(confidence, 0.95))

        intensity = min(base_intensity * intensity_mult, 1.0)

        seen.add(label)
        detected.append(EmotionSignal(
            label=label, valence=v, arousal=a,
            dominance=d, intensity=round(intensity, 3),
            confidence=round(confidence, 3), source="regex",
            cause=cause, sarcasm=sarcasm,
            multi_labels=_LABEL_TO_GOEMOTION.get(label, []),
        ))

    return detected


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 2 â€” Model-based VAD regression (centroid projection)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NOTE: improved â€” pluggable model layer. Current impl uses cosine
# distance to emotion-label centroids as a lightweight proxy for a
# BERT-VAD regressor.

_CENTROID_TEXTS: dict[str, str] = {
    "ÑÑ‚Ñ€Ğ°Ñ…": "Ğ¼Ğ½Ğµ ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾, Ñ Ğ±Ğ¾ÑÑÑŒ",
    "ÑÑ‚Ñ‹Ğ´": "Ğ¼Ğ½Ğµ ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾ Ğ·Ğ° ÑĞµĞ±Ñ",
    "Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ": "Ğ¼ĞµĞ½Ñ Ğ±ĞµÑĞ¸Ñ‚, Ñ Ğ·Ğ»ÑÑÑŒ",
    "Ğ³Ñ€ÑƒÑÑ‚ÑŒ": "Ğ¼Ğ½Ğµ Ğ³Ñ€ÑƒÑÑ‚Ğ½Ğ¾ Ğ¸ Ğ¿ĞµÑ‡Ğ°Ğ»ÑŒĞ½Ğ¾",
    "Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ": "Ñ Ñ€Ğ°Ğ´ Ğ¸ ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²",
    "Ğ²Ğ¸Ğ½Ğ°": "Ñ Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚, Ğ¼Ğ½Ğµ ÑÑ‚Ñ‹Ğ´Ğ½Ğ¾",
    "ÑƒÑÑ‚Ğ°Ğ»Ğ¾ÑÑ‚ÑŒ": "Ñ ÑƒÑÑ‚Ğ°Ğ», Ğ½ĞµÑ‚ ÑĞ¸Ğ»",
    "Ğ¾Ğ±Ğ¸Ğ´Ğ°": "Ğ¼Ğ½Ğµ Ğ¾Ğ±Ğ¸Ğ´Ğ½Ğ¾",
    "ÑÑ‚ÑƒĞ¿Ğ¾Ñ€": "Ñ Ğ² ÑÑ‚ÑƒĞ¿Ğ¾Ñ€Ğµ, Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ",
    "Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ": "Ğ¼Ğ½Ğµ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾",
    "Ğ½Ğ°Ğ´ĞµĞ¶Ğ´Ğ°": "Ñ Ğ²ĞµÑ€Ñ, Ğ²ÑÑ‘ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑÑ",
    "Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²Ğ¾": "Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº, Ğ½Ğ¸ĞºĞ¾Ğ³Ğ¾ Ñ€ÑĞ´Ğ¾Ğ¼",
}


async def _model_predict(
    text: str,
    embedding_service: Any | None,
) -> list[EmotionSignal]:
    """Layer 2: embedding-based emotion prediction with VAD interpolation.

    Instead of looking up VAD from the regex table, this version
    computes a weighted average across *all* centroids whose similarity
    exceeds 0.30 (interpolation floor) and blends the label-specific
    VAD (70 %) with the global interpolated VAD (30 %).  This gives
    actual regression from the embedding space rather than a flat
    lookup.
    """
    if embedding_service is None:
        return []

    try:
        text_emb = await embedding_service.embed_text(text)
        if text_emb is None:
            return []
    except Exception as exc:
        logger.debug("Model layer embedding failed: %s", exc)
        return []

    from core.utils.math import cosine_similarity

    # â”€â”€ compute similarities to every centroid â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    sims: list[tuple[str, float]] = []
    for label, centroid_text in _CENTROID_TEXTS.items():
        try:
            centroid_emb = await embedding_service.embed_text(centroid_text)
            if centroid_emb is None:
                continue
        except Exception:
            continue
        sim = cosine_similarity(text_emb, centroid_emb)
        sims.append((label, sim))

    if not sims:
        return []

    sims.sort(key=lambda x: x[1], reverse=True)

    # â”€â”€ global interpolated VAD from all centroids above floor â”€â”€
    relevant = [(lb, s) for lb, s in sims if s >= 0.30 and lb in _VAD_NORMS]
    total_sim = sum(s for _, s in relevant)
    if total_sim <= 0:
        return []

    v_interp = sum(_VAD_NORMS[lb][0] * s for lb, s in relevant) / total_sim
    a_interp = sum(_VAD_NORMS[lb][1] * s for lb, s in relevant) / total_sim
    d_interp = sum(_VAD_NORMS[lb][2] * s for lb, s in relevant) / total_sim

    # â”€â”€ build signals for top matches above classification gate â”€
    top_matches = [(lb, s) for lb, s in sims if s >= 0.45][:3]
    results: list[EmotionSignal] = []

    for label, sim in top_matches:
        confidence = min(0.3 + (sim - 0.45) * (0.65 / 0.35), 0.99)
        norms = _VAD_NORMS.get(label, (0.0, 0.0, 0.0, 0.5))

        # Blend label-specific VAD (70 %) with interpolated (30 %)
        blend = 0.7
        v = norms[0] * blend + v_interp * (1 - blend)
        a = norms[1] * blend + a_interp * (1 - blend)
        d = norms[2] * blend + d_interp * (1 - blend)

        results.append(EmotionSignal(
            label=label,
            valence=round(v, 3), arousal=round(a, 3), dominance=round(d, 3),
            intensity=norms[3],
            confidence=round(confidence, 3),
            source="model",
            multi_labels=_LABEL_TO_GOEMOTION.get(label, []),
        ))

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Layer 3 â€” LLM arbiter
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_LLM_EMOTION_PROMPT = """\
Ğ¢Ñ‹ â€” ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚ Ğ¿Ğ¾ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹.  ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ñ‚ĞµĞºÑÑ‚ Ğ¸ Ğ²ĞµÑ€Ğ½Ğ¸
JSON (Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON, Ğ±ĞµĞ· markdown) ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹:
{
  "emotions": [
    {
      "label": "<Ğ¼ĞµÑ‚ĞºĞ° ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼>",
      "valence": <float -1..1>,
      "arousal": <float -1..1>,
      "dominance": <float -1..1>,
      "intensity": <float 0..1>,
      "confidence": <float 0..1>,
      "cause": "<Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ¸Ğ»Ğ¸ null>",
      "sarcasm": <bool>,
      "implicit": <bool>
    }
  ]
}
ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»Ğ°:
- Ğ’ĞµÑ€Ğ½Ğ¸ Ğ¾Ñ‚ 0 Ğ´Ğ¾ 3 ÑĞ¼Ğ¾Ñ†Ğ¸Ğ¹
- implicit=true ĞµÑĞ»Ğ¸ ÑĞ¼Ğ¾Ñ†Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ° Ğ¿Ñ€ÑĞ¼Ğ¾, Ğ° ÑĞ»ĞµĞ´ÑƒĞµÑ‚ Ğ¸Ğ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
- Ğ£Ñ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ğ¹ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ¸ (ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚) Ğ¿Ñ€Ğ¸ Ğ¾Ñ†ĞµĞ½ĞºĞµ
- Ğ•ÑĞ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ½ĞµĞ¹Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ â€” Ğ²ĞµÑ€Ğ½Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ğ¼Ğ°ÑÑĞ¸Ğ² emotions
"""


async def _llm_arbitrate(
    text: str,
    context_window: list[str],
    llm_client: "LLMClient | None",
) -> list[EmotionSignal]:
    """Layer 3: invoke LLM for ambiguous/low-confidence cases."""
    if llm_client is None:
        return []

    context_block = "\n".join(f"[ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚] {msg}" for msg in context_window[-ERC_CONTEXT_WINDOW:])
    user_payload = f"{context_block}\n\n[Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ] {text}" if context_block else text

    try:
        # Use dedicated arbitrate_emotion with emotion-specific prompt
        if hasattr(llm_client, "arbitrate_emotion"):
            raw = await llm_client.arbitrate_emotion(user_payload, _LLM_EMOTION_PROMPT)
        else:
            # Fallback for older clients that lack the method
            raw = await llm_client.extract_emotion(user_payload, "FEELING_REPORT")
    except Exception as exc:
        logger.warning("LLM emotion arbiter failed: %s", exc)
        return []

    if isinstance(raw, str):
        try:
            raw = json.loads(raw)
        except json.JSONDecodeError:
            return []

    if not isinstance(raw, dict):
        return []

    emotions_raw = raw.get("emotions", [])
    if not isinstance(emotions_raw, list):
        return []

    signals: list[EmotionSignal] = []
    for item in emotions_raw[:3]:
        if not isinstance(item, dict) or "label" not in item:
            continue
        signals.append(EmotionSignal(
            label=str(item["label"]),
            valence=float(item.get("valence", 0)),
            arousal=float(item.get("arousal", 0)),
            dominance=float(item.get("dominance", 0)),
            intensity=float(item.get("intensity", 0.5)),
            confidence=float(item.get("confidence", 0.7)),
            source="llm",
            implicit=bool(item.get("implicit", False)),
            sarcasm=bool(item.get("sarcasm", False)),
            cause=item.get("cause"),
            multi_labels=_LABEL_TO_GOEMOTION.get(str(item["label"]), []),
        ))

    return signals


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ERC context window  # NOTE: improved â€” conversational context
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _build_context_window(
    session_memory: "SessionMemory | None",
    user_id: str,
) -> list[str]:
    if session_memory is None:
        return []
    ctx = session_memory.get_context(user_id, max_messages=ERC_CONTEXT_WINDOW * 2)
    return [m["text"] for m in ctx if m.get("role") == "user"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Personal baseline  # NOTE: improved â€” per-user neutral VAD point
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(slots=True)
class PersonalBaseline:
    """Per-user neutral VAD reference point (EMA)."""

    valence: float = BASELINE_V
    arousal: float = BASELINE_A
    dominance: float = BASELINE_D
    sample_count: int = 0

    def update(self, v: float, a: float, d: float, alpha: float = 0.05) -> None:
        if self.sample_count == 0:
            self.valence = v
            self.arousal = a
            self.dominance = d
        else:
            self.valence += alpha * (v - self.valence)
            self.arousal += alpha * (a - self.arousal)
            self.dominance += alpha * (d - self.dominance)
        self.sample_count += 1

    def delta(self, v: float, a: float, d: float) -> tuple[float, float, float]:
        return (v - self.valence, a - self.arousal, d - self.dominance)

    def to_dict(self) -> dict[str, Any]:
        return {
            "baseline_v": round(self.valence, 3),
            "baseline_a": round(self.arousal, 3),
            "baseline_d": round(self.dominance, 3),
            "baseline_samples": self.sample_count,
        }


_baselines: dict[str, PersonalBaseline] = {}


def get_baseline(user_id: str) -> PersonalBaseline:
    if user_id not in _baselines:
        _baselines[user_id] = PersonalBaseline()
    return _baselines[user_id]


def load_baseline_from_meta(user_id: str, meta: dict[str, Any]) -> None:
    bl = PersonalBaseline(
        valence=float(meta.get("baseline_v", BASELINE_V)),
        arousal=float(meta.get("baseline_a", BASELINE_A)),
        dominance=float(meta.get("baseline_d", BASELINE_D)),
        sample_count=int(meta.get("baseline_samples", 0)),
    )
    _baselines[user_id] = bl


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Fusion / merge logic
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _merge_signals(
    regex_signals: list[EmotionSignal],
    model_signals: list[EmotionSignal],
    llm_signals: list[EmotionSignal],
) -> list[EmotionSignal]:
    """Fuse signals from all layers: prefer higher-confidence source.

    Priority: LLM > model > regex (when same label appears).
    Also detects **ambivalence** when opposing-valence emotions
    co-occur (e.g. joy + sadness) and marks every signal accordingly.
    """
    by_label: dict[str, EmotionSignal] = {}

    for sig in regex_signals:
        by_label[sig.label] = sig
    for sig in model_signals:
        existing = by_label.get(sig.label)
        if existing is None or sig.confidence > existing.confidence:
            by_label[sig.label] = sig
    for sig in llm_signals:
        existing = by_label.get(sig.label)
        if existing is None or sig.confidence >= existing.confidence:
            by_label[sig.label] = sig

    result = [s for s in by_label.values() if s.confidence >= EMOTION_CONFIDENCE_MIN]
    result.sort(key=lambda s: s.confidence, reverse=True)

    # â”€â”€ Ambivalence detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if len(result) >= 2:
        has_pos = any(s.valence > 0.1 for s in result)
        has_neg = any(s.valence < -0.1 for s in result)
        if has_pos and has_neg:
            for s in result:
                s.ambivalent = True

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Guard regex
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_EMOTION_GUARD = re.compile(
    r"(Ğ±Ğ¾ÑÑÑŒ|ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|ÑÑ‚Ñ€Ğ°Ñ…|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ¶|Ñ‚Ñ€ĞµĞ²Ğ¾Ğ³|Ğ±ĞµÑĞ¿Ğ¾ĞºĞ¾Ğ¹|Ğ¿Ğ°Ğ½Ğ¸Ğº|Ğ½ĞµÑ€Ğ²Ğ½Ğ¸Ñ‡|Ğ²Ğ¾Ğ»Ğ½Ñƒ"
    r"|Ñ€Ğ°Ğ´|Ñ€Ğ°Ğ´Ğ¾ÑÑ‚ÑŒ|Ğ·Ğ»ÑÑÑŒ|Ğ·Ğ»Ğ¾ÑÑ‚ÑŒ|Ğ±ĞµÑˆĞµĞ½|Ñ€Ğ°Ğ·Ğ´Ñ€Ğ°Ğ¶|Ğ±ĞµÑĞ¸Ñ‚|Ğ²Ğ·Ğ±ĞµÑˆ|Ñ€Ğ°Ğ·ÑŠÑÑ€ĞµĞ½"
    r"|Ğ³Ñ€ÑƒÑÑ‚|Ğ¿ĞµÑ‡Ğ°Ğ»|Ñ‚Ğ¾ÑĞºĞ»|Ñ‚Ğ¾ÑĞº|ÑƒĞ½Ñ‹Ğ»|ÑƒĞ½Ñ‹Ğ½Ğ¸|ÑÑ‚Ñ‹Ğ´|ÑƒÑÑ‚Ğ°Ğ»|Ğ²Ñ‹Ğ¼Ğ¾Ñ‚Ğ°Ğ½|Ğ¸Ğ·Ğ¼Ğ¾Ñ‚Ğ°Ğ½"
    r"|Ğ²Ğ¸Ğ½Ğ°|Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ°Ñ‚|Ğ¾Ğ±Ğ¸Ğ´|ÑÑ‚ÑƒĞ¿Ğ¾Ñ€|Ğ·Ğ°Ğ¼ĞµÑ€|Ğ¾Ñ†ĞµĞ¿ĞµĞ½"
    r"|Ñ‡ÑƒĞ²ÑÑ‚Ğ²ÑƒÑ|Ğ½ĞµĞ½Ğ°Ğ²Ğ¸Ğ¶Ñƒ\s+ÑĞµĞ±Ñ|Ğ¿Ñ€ĞµĞ·Ğ¸Ñ€Ğ°Ñ\s+ÑĞµĞ±Ñ|Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½|Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¾|Ñ‚Ğ¾ÑˆĞ½Ğ¸Ñ‚"
    r"|Ğ¼ĞµÑ€Ğ·Ğº|Ğ³Ğ°Ğ´Ğº|Ğ½Ğ°Ğ´ĞµĞ¶Ğ´|Ğ²ĞµÑ€Ñ|Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¼|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ğº|Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡ĞµÑÑ‚Ğ²"
    r"|Ğ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½|Ğ´Ğ¾Ğ²Ğ¾Ğ»ÑŒĞ½Ğ°|ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²|Ğ²Ğ¾ÑÑ‚Ğ¾Ñ€Ğ³"
    r"|Ğ¿Ğ»Ğ¾Ñ…Ğ¾|Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾|Ğ¾Ğº)",
    re.IGNORECASE,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Public API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def extract(
    user_id: str,
    text: str,
    intent: str,
    person_id: str,
    *,
    session_memory: "SessionMemory | None" = None,
    llm_client: "LLMClient | None" = None,
    embedding_service: Any | None = None,
) -> tuple[list[Node], list[Edge]]:
    """Full emotion extraction pipeline.

    Parameters
    ----------
    user_id, text, intent, person_id : str
        Core identification / message fields.
    session_memory : SessionMemory, optional
        For ERC context window.
    llm_client : LLMClient, optional
        For Layer 3 arbitration.
    embedding_service : EmbeddingService, optional
        For Layer 2 model-based prediction.

    Returns
    -------
    tuple[list[Node], list[Edge]]
        Emotion/Soma nodes and FEELS/EXPRESSED_AS edges.
    """
    nodes: list[Node] = []
    edges: list[Edge] = []
    lowered = text.lower()

    # ERC context window  # NOTE: improved â€” contextual emotion recognition
    context_window = _build_context_window(session_memory, user_id)

    # â”€â”€ Layer 1: regex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    regex_signals = _detect_emotions(lowered)

    # Guard: skip deep layers if no emotional keywords AND intent
    # is not feeling-related.
    if not regex_signals and not _EMOTION_GUARD.search(lowered):
        if intent not in ("FEELING_REPORT", "REFLECTION"):
            return nodes, edges

    # â”€â”€ Layer 2: model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    model_signals = await _model_predict(text, embedding_service)

    # â”€â”€ Layer 3: LLM arbiter (conditional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    llm_signals: list[EmotionSignal] = []
    needs_arbiter = (
        (regex_signals and all(s.confidence < LLM_ARBITER_THRESHOLD for s in regex_signals))
        or _detect_sarcasm(lowered)
        or (
            regex_signals
            and model_signals
            and regex_signals[0].label != model_signals[0].label
        )
        or (not regex_signals and intent == "FEELING_REPORT")
        or (
            not regex_signals
            and len(context_window) >= IMPLICIT_MIN_CONTEXT
            and intent in ("FEELING_REPORT", "REFLECTION")
        )
    )
    if needs_arbiter:
        llm_signals = await _llm_arbitrate(text, context_window, llm_client)

    # â”€â”€ Fusion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    merged = _merge_signals(regex_signals, model_signals, llm_signals)

    if not merged:
        return nodes, edges

    # â”€â”€ Personal baseline update â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    baseline = get_baseline(user_id)
    for sig in merged:
        baseline.update(sig.valence, sig.arousal, sig.dominance)

    # â”€â”€ Build nodes & edges â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # NOTE: improved â€” key is now None (unique UUID per signal)
    # instead of date-based key that collapsed intra-session trajectory.
    now_iso = datetime.now(timezone.utc).isoformat()
    emotion_nodes: list[Node] = []

    for sig in merged:
        dv, da, dd = baseline.delta(sig.valence, sig.arousal, sig.dominance)
        meta = sig.to_metadata()
        meta["delta_v"] = round(dv, 3)
        meta["delta_a"] = round(da, 3)
        meta["delta_d"] = round(dd, 3)
        meta["created_at"] = now_iso

        emotion = Node(
            user_id=user_id,
            type="EMOTION",
            key=None,
            metadata=meta,
        )
        emotion_nodes.append(emotion)
        nodes.append(emotion)
        edges.append(Edge(
            user_id=user_id,
            source_node_id=person_id,
            target_node_id=emotion.id,
            relation="FEELS",
        ))

    # â”€â”€ Somatic markers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    body_match = re.search(
        r"\b(Ğ² Ğ³Ñ€ÑƒĞ´Ğ¸|Ğ² Ğ¶Ğ¸Ğ²Ğ¾Ñ‚Ğµ|Ğ² Ğ³Ğ¾Ñ€Ğ»Ğµ|Ğ² Ğ¿Ğ»ĞµÑ‡Ğ°Ñ…|Ğ² ÑˆĞµĞµ|Ğ² Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğµ|Ğ² ÑĞ¿Ğ¸Ğ½Ğµ)\b",
        lowered,
    )
    if body_match:
        location = body_match.group(1)
        soma = Node(
            user_id=user_id,
            type="SOMA",
            key=None,
            metadata={"location": location, "sensation": "tension"},
        )
        nodes.append(soma)
        if emotion_nodes:
            edges.append(Edge(
                user_id=user_id,
                source_node_id=emotion_nodes[0].id,
                target_node_id=soma.id,
                relation="EXPRESSED_AS",
            ))

    return nodes, edges
